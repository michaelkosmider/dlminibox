{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea63530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl import Module, Variable\n",
    "from dl.modules import Convolution, ReLU, Linear, Flatten, MaxPool\n",
    "from dl.functions import cross_entropy_loss\n",
    "\n",
    "# Downloading CIFAR-10\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "# Training\n",
    "from dl.data import BatchLoader, train_val_split\n",
    "from dl.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763036d",
   "metadata": {},
   "source": [
    "## Download and extract CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9420cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CIFAR-10 is ready at: ./data/cifar-10-batches-py\n"
     ]
    }
   ],
   "source": [
    "root = './data'\n",
    "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "filename = 'cifar-10-python.tar.gz'\n",
    "archive_path = os.path.join(root, filename)\n",
    "extract_path = os.path.join(root, 'cifar-10-batches-py')\n",
    "\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "# Download compressed file containing dataset.\n",
    "if not os.path.exists(archive_path):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(archive_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "# Extract dataset from compressed file.\n",
    "if not os.path.exists(extract_path):\n",
    "    with tarfile.open(archive_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=os.path.dirname(extract_path))\n",
    "\n",
    "print(f\"\\nCIFAR-10 is ready at: {extract_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e41c6c5",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 into ram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c8321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_batch(batch_path):\n",
    "    with open(batch_path, 'rb') as fo:\n",
    "        batch = pickle.load(fo, encoding='bytes')\n",
    "        X = batch[b'data'] # shape (10000, 3072)\n",
    "        X = X.reshape(-1, 3, 32, 32).astype(np.float32)\n",
    "        y = np.array(batch[b'labels']) # list of 10000 ints\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Iterate over all 5 batch files.\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(1, 6): \n",
    "    batch_path = os.path.join(extract_path, f'data_batch_{i}')\n",
    "    with open(batch_path, 'rb') as fo:\n",
    "        X, y = load_cifar_batch(batch_path)\n",
    "\n",
    "    xs.append(X)\n",
    "    ys.append(y)\n",
    "\n",
    "X_train_full = np.concatenate(xs)  # shape (50000, 3, 32, 32)\n",
    "y_train_full = np.concatenate(ys)\n",
    "X_test, y_test = load_cifar_batch(os.path.join(extract_path, 'test_batch'))\n",
    "\n",
    "# Normalize\n",
    "X_train_full = (X_train_full / 255.0 - 0.5) / 0.5  # normalize to [-1, 1]\n",
    "X_test = (X_test / 255.0 - 0.5) / 0.5\n",
    "\n",
    "# Set aside a validation set.\n",
    "X_train, y_train, X_val, y_val = train_val_split(X_train_full, y_train_full, ratio=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff392c",
   "metadata": {},
   "source": [
    "## Create BatchLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1314ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10:\n",
    "    \n",
    "    def __init__(self, images, labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Variable(self.images[idx])\n",
    "        label = Variable(self.labels[idx])\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90756bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchloaders = {}\n",
    "batchloaders['train'] = BatchLoader(Cifar10(X_train, y_train), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77751abe",
   "metadata": {},
   "source": [
    "## Define the CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acda34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Conv Block 1\n",
    "        self.conv1 = Convolution(C_in=3, C_out=32, K=3, stride=1, padding=1)\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1 = MaxPool(K=2, stride=2)  # 32x32 → 16x16\n",
    "\n",
    "        # Conv Block 2\n",
    "        self.conv2 = Convolution(C_in=32, C_out=64, K=3, stride=1, padding=1)\n",
    "        self.relu2 = ReLU()\n",
    "        self.pool2 = MaxPool(K=2, stride=2)  # 16x16 → 8x8\n",
    "\n",
    "        # Conv Block 3\n",
    "        self.conv3 = Convolution(C_in=64, C_out=128, K=3, stride=1, padding=1)\n",
    "        self.relu3 = ReLU()\n",
    "        self.pool3 = MaxPool(K=2, stride=2)  # 8x8 → 4x4\n",
    "\n",
    "        self.flat = Flatten()\n",
    "        self.fc1 = Linear(128 * 4 * 4, 256)\n",
    "        self.relu4 = ReLU()\n",
    "        self.fc2 = Linear(256, 10)  # CIFAR-10 output\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.pool1(self.relu1(self.conv1(X)))\n",
    "        X = self.pool2(self.relu2(self.conv2(X)))\n",
    "        X = self.pool3(self.relu3(self.conv3(X)))\n",
    "        X = self.flat(X)\n",
    "        X = self.relu4(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a69728",
   "metadata": {},
   "source": [
    "## Train the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c777bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "optimizer = SGD(model.parameters(), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbe7ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.065007252117097\n",
      "2.6299327416531906\n",
      "2.7263070892227765\n",
      "2.652463272976955\n",
      "2.8266908278827514\n",
      "2.4197886126932575\n",
      "2.547659512805119\n",
      "2.506274184922236\n",
      "2.368560455235001\n",
      "2.4320414109541213\n",
      "2.3935675471947078\n",
      "2.250594616087179\n",
      "2.293514366483207\n",
      "2.4725810834047968\n",
      "2.3722562954657893\n",
      "2.24253641759704\n",
      "2.304320559349934\n",
      "2.365328866666954\n",
      "2.444685288383788\n",
      "2.291654912405363\n",
      "2.3951446511777816\n",
      "2.217830627479435\n",
      "2.2995342133312895\n",
      "2.2322434075397135\n",
      "2.258606528482956\n",
      "2.3775843401450585\n",
      "2.3240797440832184\n",
      "2.2630782386449604\n",
      "2.313221024890109\n",
      "2.338662485335516\n",
      "2.27288847048003\n",
      "2.248596405124302\n",
      "2.344184322405588\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batchloaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Compute features and loss.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# print(X_batch)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     loss \u001b[38;5;241m=\u001b[39m cross_entropy_loss(features, y_batch)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Development/dlminibox/dlminibox_code/dl/module.py:23\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     26\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(X)))\n\u001b[1;32m     27\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(X)))\n\u001b[0;32m---> 28\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     29\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat(X)\n\u001b[1;32m     30\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu4(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(X))\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Development/dlminibox/dlminibox_code/dl/module.py:23\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Development/dlminibox/dlminibox_code/dl/modules/convolution.py:29\u001b[0m, in \u001b[0;36mConvolution.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Reshape X and W to compute convolution as a matrix multiplication. Also add padding beforehand.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     X_padded \u001b[38;5;241m=\u001b[39m pad_and_dilate(X\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n\u001b[0;32m---> 29\u001b[0m     X_rows \u001b[38;5;241m=\u001b[39m \u001b[43mim2row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     W_columns \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW\u001b[38;5;241m.\u001b[39mdata, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC_in \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK)\n\u001b[1;32m     33\u001b[0m     )\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Perform the matrix multiplication and reshape.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Development/dlminibox/dlminibox_code/dl/modules/convolution.py:152\u001b[0m, in \u001b[0;36mim2row\u001b[0;34m(X, C_in, K, stride)\u001b[0m\n\u001b[1;32m    149\u001b[0m X_windows \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(X_windows, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    150\u001b[0m X_windows \u001b[38;5;241m=\u001b[39m X_windows[:, ::stride, ::stride]\n\u001b[0;32m--> 152\u001b[0m X_rows \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Memory intensive step: every window in the image is now explicitly copied into its own row.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_rows\n",
      "File \u001b[0;32m~/miniconda3/envs/personal_torch/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:324\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, shape, order, newshape, copy)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m'\u001b[39m, shape, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/personal_torch/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in batchloaders['train']:\n",
    "    \n",
    "    # Compute features and loss.\n",
    "    # print(X_batch)\n",
    "    features = model(X_batch)\n",
    "    loss = cross_entropy_loss(features, y_batch)\n",
    "\n",
    "    print(loss.data)\n",
    "\n",
    "    # Update model parameters.\n",
    "    optimizer.clear_grad()\n",
    "    loss.backward()\n",
    "    optimizer.update_parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
